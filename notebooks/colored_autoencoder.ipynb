{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os, sys # filesystem operations\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from argparse import Namespace\n",
    "import matplotlib.pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fiximg(orig_img):\n",
    "    size0=orig_img.size[0]\n",
    "    size1=orig_img.size[1]\n",
    "    desired_size=(img_size, img_size)\n",
    "    #if size0 != size1:\n",
    "    #    if size0<size1:\n",
    "    #        desired_size=(size0,size0)\n",
    "    #    else:\n",
    "    #        desired_size=(size1,size1)\n",
    "    old_size = orig_img.size\n",
    "    new_size = (desired_size[0],desired_size[1])\n",
    "    padded_image = Image.new(\"RGB\", new_size, color=\"white\")\n",
    "    padded_image.paste(orig_img, ((new_size[0] - old_size[0]) // 2, (new_size[1] - old_size[1]) // 2))\n",
    "    orig_img=padded_image\n",
    "    return orig_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how to get a random flower\n",
    "input_dir = '.'\n",
    "#dataset_dir = os.path.join(input_dir,'UnstableNetGen/notebooks/102flowers')\n",
    "dataset_dir='102flowers/jpg/'\n",
    "random_number = np.random.randint(1, 8190)\n",
    "print(random_number)\n",
    "img_name='image_0'+str(random_number).zfill(4)+'.jpg'\n",
    "imgpath=os.path.join(dataset_dir,img_name)\n",
    "orig_img = Image.open(imgpath)\n",
    "orig_img=fiximg(orig_img)\n",
    "print(np.shape(orig_img))\n",
    "plt.imshow(orig_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DS():\n",
    "    def __init__(self,min, max):\n",
    "        self.min=min\n",
    "        self.max=max\n",
    "        self.dataset_dir = os.path.join(input_dir,'102flowers/jpg/')\n",
    "        random_number = np.random.randint(1, 8190)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.max-self.min\n",
    "    def __getitem__(self, idx):\n",
    "        #class_id = torch.as_tensor(self.categories.index(self.labels[idx]), dtype=torch.int64)\n",
    "        number=idx+self.min\n",
    "        img_name='image_0'+str(number).zfill(4)+'.jpg'\n",
    "        imgpath=os.path.join(self.dataset_dir,img_name)\n",
    "        orig_img = Image.open(imgpath)\n",
    "        orig_img=fiximg(orig_img)\n",
    "        shaper=np.shape(orig_img)\n",
    "        img=np.reshape(orig_img, (shaper[0]*shaper[1]*shaper[2], -1))/255.0\n",
    "        return torch.tensor(img).T\n",
    "train_data=DS(1, 8000)\n",
    "print(train_data[0].shape)\n",
    "test_data=DS(8001, 8190)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.dense_layer1 = nn.Linear(in_features=img_size*img_size*3, out_features=5124)\n",
    "        self.dense_layer2 = nn.Linear(in_features=5124, out_features=1024)\n",
    "        #self.dense_layer3 = nn.Linear(in_features=1024, out_features=512)\n",
    "        #self.dense_layer4 = nn.Linear(in_features=512, out_features=256)\n",
    "        #self.dense_layer5 = nn.Linear(in_features=256, out_features=128)\n",
    "        self.dense_layer6 = nn.Linear(in_features=1024, out_features=108)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.dense_layer1(x))\n",
    "        x = F.leaky_relu(self.dense_layer2(x))\n",
    "        #x = F.leaky_relu(self.dense_layer3(x))\n",
    "        #x = F.leaky_relu(self.dense_layer4(x))\n",
    "        #x = F.leaky_relu(self.dense_layer5(x))\n",
    "        x = F.leaky_relu(self.dense_layer6(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dense_layer001 = nn.Linear(in_features=108, out_features=1024)\n",
    "        #self.dense_layer01 = nn.Linear(in_features=128, out_features=256)\n",
    "        #self.dense_layer1 = nn.Linear(in_features=256, out_features=512)\n",
    "        #self.dense_layer2 = nn.Linear(in_features=512, out_features=1024)\n",
    "        self.dense_layer3 = nn.Linear(in_features=1024, out_features=5124)\n",
    "        self.dense_layer4 = nn.Linear(in_features=5124, out_features=img_size*img_size*3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.dense_layer001(x))\n",
    "        #x = F.leaky_relu(self.dense_layer01(x))\n",
    "        #x = F.leaky_relu(self.dense_layer1(x))\n",
    "        #x = F.leaky_relu(self.dense_layer2(x))\n",
    "        x = F.leaky_relu(self.dense_layer3(x))\n",
    "        x = F.leaky_relu(self.dense_layer4(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "myEncoder=Encoder()\n",
    "myDecoder=Decoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "myModel = Autoencoder(myEncoder, myDecoder)\n",
    "myModel = myModel.to(device)\n",
    "train_dl=torch.utils.data.DataLoader(train_data, batch_size=2, shuffle=True)\n",
    "test_dl=torch.utils.data.DataLoader(test_data, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, train_dl, num_epochs, iteration):\n",
    "    # Loss Function, Optimizer and Scheduler  \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=0.0001)#01)\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.001,\n",
    "                                                steps_per_epoch=int(len(train_dl)),\n",
    "                                                epochs=num_epochs)\n",
    "\n",
    "    # Repeat for each epoch\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct_prediction = 0\n",
    "        total_prediction = 0\n",
    "\n",
    "        # Repeat for each batch in the training set\n",
    "        for i, data in enumerate(train_dl):\n",
    "            # Get the input features and target labels, and put them on the GPU\n",
    "            inputs = data[0].to(device)\n",
    "            inputs = inputs.to(torch.float32)\n",
    "            #print(labels.is_cuda)\n",
    "            #print(np.shape(inputs))\n",
    "            # Normalize the inputs\n",
    "            #inputs_m, inputs_s = inputs.mean(), inputs.std()\n",
    "            #inputs = (inputs - inputs_m) / inputs_s\n",
    "            #print(inputs.is_cuda)\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            #print(outputs.is_cuda)\n",
    "            loss = criterion(outputs, inputs)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            # Keep stats for Loss and Accuracy\n",
    "            running_loss += loss.item()\n",
    "        print(running_loss)\n",
    "        print(epoch)\n",
    "for i in range(1):\n",
    "    num_epochs=10\n",
    "    iteration=i\n",
    "    training(myModel, train_dl, num_epochs, iteration)\n",
    "    #trainingacclist.append(trainacc)\n",
    "    \n",
    "    #temp1, temp2, testacc=inference(myModel, test_dl)\n",
    "    #testacclist.append(testacc)\n",
    "#x_axis = list(range(1, len(testacclist) + 1))\n",
    "#plt.plot(x_axis, trainingacclist, x_axis, testacclist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(test_dl):\n",
    "    # Get the input features and target labels, and put them on the GPU\n",
    "    inputs = data[0].to(device)\n",
    "    inputs = inputs.to(torch.float32)\n",
    "    break\n",
    "\n",
    "orig=inputs.reshape(img_size,img_size, 3)\n",
    "output=myEncoder(inputs)\n",
    "\n",
    "output=myDecoder(output)\n",
    "#print(output)\n",
    "output=output.detach().cpu().numpy()\n",
    "output=output.reshape(img_size,img_size,3)\n",
    "matplotlib.pyplot.subplot(2, 2, 1)\n",
    "matplotlib.pyplot.imshow(orig.detach().cpu())\n",
    "matplotlib.pyplot.subplot(2, 2, 2)\n",
    "matplotlib.pyplot.imshow(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
