{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os, sys # filesystem operations\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from argparse import Namespace\n",
    "import tensorflow.keras.datasets\n",
    "import matplotlib.pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n"
     ]
    }
   ],
   "source": [
    "# Preparing MNIST Dataset\n",
    "(x_train_orig, y_train), (x_test_orig, y_test) = tensorflow.keras.datasets.mnist.load_data()\n",
    "x_train_orig = x_train_orig.astype(\"float32\") / 255.0\n",
    "x_test_orig = x_test_orig.astype(\"float32\") / 255.0\n",
    "x_train = np.reshape(x_train_orig, newshape=(x_train_orig.shape[0], np.prod(x_train_orig.shape[1:])))\n",
    "x_test = np.reshape(x_test_orig, newshape=(x_test_orig.shape[0], np.prod(x_test_orig.shape[1:])))\n",
    "print(set(y_train))\n",
    "class DS():\n",
    "    def __init__(self, x_data, y_data):\n",
    "        self.data=x_data\n",
    "        self.labels=y_data\n",
    "        self.categories=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        #class_id = torch.as_tensor(self.categories.index(self.labels[idx]), dtype=torch.int64)\n",
    "        img=self.data[idx]\n",
    "        return torch.tensor(img), torch.tensor(img)\n",
    "train_data=DS(x_train, x_train)\n",
    "test_data=DS(x_test, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.dense_layer1 = nn.Linear(in_features=784, out_features=300)\n",
    "        self.dense_layer2 = nn.Linear(in_features=300, out_features=4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.dense_layer1(x))\n",
    "        x = F.leaky_relu(self.dense_layer2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dense_layer1 = nn.Linear(in_features=4, out_features=300)\n",
    "        self.dense_layer2 = nn.Linear(in_features=300, out_features=784)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.dense_layer1(x))\n",
    "        x = F.leaky_relu(self.dense_layer2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "myEncoder=Encoder()\n",
    "myDecoder=Decoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "myModel = Autoencoder(myEncoder, myDecoder)\n",
    "myModel = myModel.to(device)\n",
    "train_dl=torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_dl=torch.utils.data.DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference (model, val_dl):\n",
    "    all_preds=[]\n",
    "    all_labels=[]\n",
    "    correct_prediction = 0\n",
    "    total_prediction = 0\n",
    "\n",
    "    # Disable gradient updates\n",
    "    with torch.no_grad():\n",
    "        for data in val_dl:\n",
    "            # Get the input features and target labels, and put them on the GPU\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            # Normalize the inputs\n",
    "            inputs_m, inputs_s = inputs.mean(), inputs.std()\n",
    "            inputs = (inputs - inputs_m) / inputs_s\n",
    "\n",
    "            # Get predictions\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Get the predicted class with the highest score\n",
    "            _, prediction = torch.max(outputs,1)\n",
    "            # Count of predictions that matched the target label\n",
    "            correct_prediction += (prediction == labels).sum().item()\n",
    "            total_prediction += prediction.shape[0]\n",
    "            \n",
    "            all_preds.append(prediction.to(torch.device(\"cpu\")))\n",
    "            all_labels.append(labels.to(torch.device(\"cpu\")))\n",
    "    acc = correct_prediction/total_prediction\n",
    "    print(f'Accuracy: {acc:.2f}, Total items: {total_prediction}')\n",
    "    return all_preds, all_labels, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "testacclist=[]\n",
    "trainingacclist=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.9656413756311\n",
      "0\n",
      "49.56025554984808\n",
      "1\n",
      "44.864938113838434\n",
      "2\n",
      "42.38763899356127\n",
      "3\n",
      "40.58319192752242\n",
      "4\n",
      "38.969721000641584\n",
      "5\n",
      "36.74191705696285\n",
      "6\n",
      "35.18011920526624\n",
      "7\n",
      "34.31420327350497\n",
      "8\n",
      "33.699611300602555\n",
      "9\n",
      "33.207565043121576\n",
      "10\n",
      "32.78668343089521\n",
      "11\n",
      "32.402552938088775\n",
      "12\n",
      "32.059030044823885\n",
      "13\n",
      "31.75795336253941\n",
      "14\n",
      "31.495158463716507\n",
      "15\n",
      "31.27448088862002\n",
      "16\n",
      "31.057022120803595\n",
      "17\n",
      "30.870098054409027\n",
      "18\n",
      "30.70233784429729\n",
      "19\n",
      "30.551954874768853\n",
      "20\n",
      "30.41359177418053\n",
      "21\n",
      "30.27845099940896\n",
      "22\n",
      "30.16613653115928\n",
      "23\n",
      "30.050598800182343\n",
      "24\n",
      "29.94777464494109\n",
      "25\n",
      "29.85122424736619\n",
      "26\n",
      "29.76294729858637\n",
      "27\n",
      "29.67824352160096\n",
      "28\n",
      "29.60676246136427\n",
      "29\n",
      "29.53520407155156\n",
      "30\n",
      "29.470649756491184\n",
      "31\n",
      "29.41112246736884\n",
      "32\n",
      "29.355496557429433\n",
      "33\n",
      "29.300834205001593\n",
      "34\n",
      "29.257470656186342\n",
      "35\n",
      "29.212770150974393\n",
      "36\n",
      "29.176544316112995\n",
      "37\n",
      "29.143038479611278\n",
      "38\n",
      "29.1128992959857\n",
      "39\n"
     ]
    }
   ],
   "source": [
    "def training(model, train_dl, num_epochs, iteration):\n",
    "    # Loss Function, Optimizer and Scheduler  \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=0.0001)#01)\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.0002,\n",
    "                                                steps_per_epoch=int(len(train_dl)),\n",
    "                                                epochs=num_epochs,\n",
    "                                                anneal_strategy='linear')\n",
    "\n",
    "    # Repeat for each epoch\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct_prediction = 0\n",
    "        total_prediction = 0\n",
    "\n",
    "        # Repeat for each batch in the training set\n",
    "        for i, data in enumerate(train_dl):\n",
    "            # Get the input features and target labels, and put them on the GPU\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            #print(labels.is_cuda)\n",
    "            #print(np.shape(inputs))\n",
    "            # Normalize the inputs\n",
    "            #inputs_m, inputs_s = inputs.mean(), inputs.std()\n",
    "            #inputs = (inputs - inputs_m) / inputs_s\n",
    "            #print(inputs.is_cuda)\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            #print(outputs.is_cuda)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            # Keep stats for Loss and Accuracy\n",
    "            running_loss += loss.item()\n",
    "        print(running_loss)\n",
    "        print(epoch)\n",
    "for i in range(1):\n",
    "    num_epochs=40\n",
    "    iteration=i\n",
    "    training(myModel, train_dl, num_epochs, iteration)\n",
    "    #trainingacclist.append(trainacc)\n",
    "    \n",
    "    #temp1, temp2, testacc=inference(myModel, test_dl)\n",
    "    #testacclist.append(testacc)\n",
    "#x_axis = list(range(1, len(testacclist) + 1))\n",
    "#plt.plot(x_axis, trainingacclist, x_axis, testacclist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 4.7161,  4.6888,  0.7444, -1.7406], grad_fn=<LeakyReluBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x14b5024f0d0>"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeUAAADWCAYAAADvqZrVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/OQEPoAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAbT0lEQVR4nO3df2zU9R3H8de1tAdIe7WUtlSLFvwZmZgw6BqU4GioLDEiLFG3LDANRlZIkCxubIoTt3XTxBEdY/9M0GTIRjIwkoxFK5QQQQOCBDEVTDcQbFW29kql11/f/UG42fH5wH3b7/U+d/d8JN+Ee9+X732+9+P97ve+7+/nQp7neQIAACmXk+oBAACACyjKAAA4gqIMAIAjKMoAADiCogwAgCMoygAAOIKiDACAIyjKAAA4gqIMAIAjKMoAADhiVLI2vH79ej3//PNqbW3VtGnT9NJLL2nmzJlX/H8DAwM6c+aMCgoKFAqFkjU8YEg8z1NnZ6cqKiqUk8PftEEbat6QyB1wW8K5w0uCLVu2ePn5+d7LL7/sffjhh97SpUu9oqIir62t7Yr/99SpU54kFhanl1OnTiXjo5PVhpM3PI/cwZIey5VyR8jzgv9Biurqas2YMUO///3vJV34C7ayslIrVqzQT3/608v+346ODhUVFQU9JCBQ7e3tikQiqR5GRhlO3pD+lztyc3MTPlL2e0TtN13atm/bjt/1g3pcv9sJimv7lcznx/M89fX1XTF3BP71dU9Pjw4ePKjVq1fHYzk5OaqtrdW+ffsuWT8WiykWi8Vvd3Z2Bj0kIHB8PRosv3lDsueOUCiUtKLsl9/tBzUe17YTFNf2ayjbudL/Cfyk2Jdffqn+/n6VlZUNipeVlam1tfWS9RsaGhSJROJLZWVl0EMC4Di/eUMidyAzpbxTZfXq1ero6Igvp06dSvWQAKQBcgcyUeBfX5eUlCg3N1dtbW2D4m1tbSovL79k/XA4rHA4HPQwAKQRv3lDIncgMwV+pJyfn6/p06ersbExHhsYGFBjY6NqamqCfjgAGSDIvHHxnHIii+d5xsXvtm1s2/e7Hb/87pff7QS12KTq9Ur2dhKRlOuUV61apcWLF+ub3/ymZs6cqXXr1qmrq0s//OEPk/FwADIAeQNIUlF+4IEH9MUXX2jNmjVqbW3VHXfcoZ07d17SxAEAF5E3ACkp1ykPRzQa5fpPOK+jo0OFhYWpHga+5mLuyMvLS/irRb/XC/vdjk2yt5/uUnWddVDvB9u2e3t7r5g7Ut59DQAALqAoAwDgiKT9IAUAuCKoaS2D6rhN9tfRtu37fVy/z4NrM4Cl6nkezvPAkTIAAI6gKAMA4AiKMgAAjqAoAwDgCIoyAACOoPsaQMZzrSs4KEF1Fw8MDKRkOzk5wRwXpur19dO9n+hrxZEyAACOoCgDAOAIijIAAI6gKAMA4AiKMgAAjqD7GkBGSeZ8x0Ft29Z1HFQXtE1Q40/VdtJlrnLmvgYAIANQlAEAcARFGQAAR1CUAQBwROBF+Re/+IVCodCg5ZZbbgn6YQBkEPIGcEFSuq9vu+02vfXWW/97kFE0eQO4vFTkDb/dvEEJqsvab5dvbm6uMe53f/2uH9Qc18kep9/nMxlzXyflXT9q1CiVl5cnY9MAMhR5A0jSOeXjx4+roqJCkydP1ve//32dPHnSum4sFlM0Gh20AMg+fvKGRO5AZgq8KFdXV2vTpk3auXOnNmzYoJaWFt11113q7Ow0rt/Q0KBIJBJfKisrgx4SAMf5zRsSuQOZKeQl+eRJe3u7rrvuOr3wwgt65JFHLrk/FospFovFb0ejUT5ccF5HR4cKCwtTPYyMdaW8Idlzx6hRoxI+N5iqc8quydRzyn4l+5xyX1/fFXNH0jspioqKdNNNN+nEiRPG+8PhsMLhcLKHASCNXClvSOQOZKakF+Vz587pk08+0Q9+8INkPxSADBF03gjqiNjvdvLz843xgoICY3z06NHGuK1rur+/3xi3da53d3cb47Y/bvLy8oxxm66uLmO8ra3NGE/282+TqsdNRODnlH/84x+rqalJ//znP/XOO+/o/vvvV25urh566KGgHwpAhiBvABcEfqT86aef6qGHHtLZs2c1YcIE3Xnnndq/f78mTJgQ9EMByBDkDeCCwIvyli1bgt4kgAxH3gAuYO5rAAAcQVEGAMARTEo9gn7+858b49OnTzfGf/WrXxnjx48fN8ZtMxrZOjrnzZtnjL/88svGeG1trTF++PBhYxxwRbLnQLZ1R9u6oEtKSozxSCRijE+cONEYv+qqq4zxcePGGeO2rm/bdbO27utz584Z46dPnzbGW1pajPF33nnHGO/r6zPG/UrV9eZ+3z9fx5EyAACOoCgDAOAIijIAAI6gKAMA4AiKMgAAjkj6r0T5FY1GrR2I6c42T63fl+Cjjz4yxr/44gtj3Nahaev6tnnttdeM8Wyc15xfiXLPxdzh51eigjJ27Fhj/MYbbzTGq6qqjPEbbrjBGL/++uuNcVuutO1/T0+PMW7LTbaucltOsc2tfeTIEWN8165dxvj7779vjNvYcmhQXfdB/HqU53nq7e29Yu7gSBkAAEdQlAEAcARFGQAAR1CUAQBwBEUZAABHMPd1Grr11lt9xW2dg347E7/73e8a488++6wx/vHHH/vaPhCEUCiUcLes38/AmDFjjPFrrrnGGC8rKzPGJ0+ebIzbuq9tn+2Ojg5j3PbZO3XqlDFu67K27a9t/JWVlca4rbvbNh5bt3ZQc2Inuzvf9L5K9L3GkTIAAI6gKAMA4AiKMgAAjqAoAwDgCN9Fec+ePbr33ntVUVGhUCik7du3D7rf8zytWbNGEydO1JgxY1RbW6vjx48HNV4AaYi8ASTGd/d1V1eXpk2bpocfflgLFy685P7nnntOL774ol555RVVVVXpqaeeUl1dnY4dO6bRo0cHMmjX1dXVBbKdpUuXGuM1NTXG+F133WWM33TTTYGMJy8vzxgfNYomflxeqvNGUFP827p/bXFbV7NtzuoJEyYY47Yu6wMHDhjjR48eNcbb29uNcdvzU15eboyPHz/eGLd1j998883G+AcffGCM27rWT58+bYzbBDFn9UjznU3nz5+v+fPnG+/zPE/r1q3Tk08+qfvuu0+S9Oqrr6qsrEzbt2/Xgw8+OLzRAkhL5A0gMYGeU25paVFra6tqa2vjsUgkourqau3bt8/4f2KxmKLR6KAFQPYYSt6QyB3ITIEW5dbWVkmXfvVQVlYWv+//NTQ0KBKJxBfbxecAMtNQ8oZE7kBmSnn39erVq9XR0RFfbDO8AMDXkTuQiQItyhebAtra2gbF29rarA0D4XBYhYWFgxYA2WMoeUMidyAzBdo2W1VVpfLycjU2NuqOO+6QJEWjUb377rtatmxZkA/lNNu8sH7t2LHDGN+4caMxXlxcbIxfLrGZ7NmzxxgvKirytR0gEUHnjaA6rU1sXdY9PT3GeHd3tzFu66a2xTs7O43x5uZmY/zDDz/0NR7bFRS25/Ls2bPG+Pnz543xiRMnGuO2bvP8/HxjPF0Mp4vbd1E+d+6cTpw4Eb/d0tKiw4cPq7i4WJMmTdLKlSv1y1/+UjfeeGP80oaKigotWLBgyIMEkN7IG0BifBflAwcO6O67747fXrVqlSRp8eLF2rRpk5544gl1dXXp0UcfVXt7u+68807t3Lkza65RBnAp8gaQGN9Fec6cOZf9eigUCmnt2rVau3btsAYGIHOQN4DEpLz7GgAAXEBRBgDAEUxanAQ5Oea/dWzxgYGBQB733//+t6+4TX9/vzFu6yi0dX0DqRAKhS55rwbVkW3bjm2SE9sczrbt2D57ttnKbN3Uti7xsWPHGuO2y8lsn23blRi2LuuCggJfj2vrZk9mZ/3ltj+Sc2JzpAwAgCMoygAAOIKiDACAIyjKAAA4gqIMAIAj6L5OAls3tS2e7I5Cv2zjscUfeOABY3zv3r2BjQkYDlv3bFCfPVvX9JkzZ4zxkydPGuO2bmdb7rB1d9v213YFiK0r27Z9W9e0revbNre2zblz53ytH5SguqxN76tE32scKQMA4AiKMgAAjqAoAwDgCIoyAACOoCgDAOAIuq8BZLxkz31t69q1zYl94sQJY3zcuHHGeElJiTFu65q+5pprjHG/Xeh5eXnG+Pnz543x3t5eY9zWTd3e3m6M5+bmGuNBGcm5rP3iSBkAAEdQlAEAcARFGQAAR1CUAQBwhO+ivGfPHt17772qqKhQKBTS9u3bB92/ZMmS+I+MX1zuueeeoMYLIA2RN4DE+O6+7urq0rRp0/Twww9r4cKFxnXuuecebdy4MX47HA4PfYRp6LPPPjPGbfPgTpw4MZnDAVKOvDHYBx98YIx/+eWXxnhpaakxbpsTe/To0ca4rbvbNje1bS5u2xzX//nPf4xxWxe3rQvatl9+u6ZT9bsCw+nu9l2U58+fr/nz5192nXA4rPLy8iEPCkBmIW8AiUnKOeXdu3ertLRUN998s5YtW6azZ89a143FYopGo4MWANnHT96QyB3ITIEX5XvuuUevvvqqGhsb9dvf/lZNTU2aP3++9afNGhoaFIlE4ktlZWXQQwLgOL95QyJ3IDMFPqPXgw8+GP/3N77xDd1+++2aMmWKdu/erblz516y/urVq7Vq1ar47Wg0yocLyDJ+84ZE7kBmSvolUZMnT1ZJSYl1WrlwOKzCwsJBC4DsdqW8IZE7kJmSPvf1p59+qrNnz2ZVh/H/X+5x0ccff2yML1u2zBi3zS8LZLrh5A1Tx226dO2ePn3aVzzZqqqqjPEpU6YY49XV1cZ4UVGRMW6bK9vWrW2TqrnNk8F3UT537tygv15bWlp0+PBhFRcXq7i4WM8884wWLVqk8vJyffLJJ3riiSd0ww03qK6uLtCBA0gf5A0gMb6L8oEDB3T33XfHb188p7N48WJt2LBBR44c0SuvvKL29nZVVFRo3rx5evbZZzP6mkMAl0feABLjuyjPmTPnsl8V/OMf/xjWgABkHvIGkBjmvgYAwBEUZQAAHJH07mv8z7Fjx4zxFStWjPBILs/WaTiSHYjAUF38QYuvS1U3td9uXtfmam5paTHGbXNi2yZ7sV2uNmbMGGPc1pUdFL/P80h2ZXOkDACAIyjKAAA4gqIMAIAjKMoAADiCogwAgCPovsYlbJ2GqeoMBUZaUJ+BoLaTqm5t2+P29PQY4+PGjTPGr776amO8r6/PGO/u7k5gdP8T1PPgwhUmHCkDAOAIijIAAI6gKAMA4AiKMgAAjqAoAwDgCLqvAWSUIDpxk92F63eMAwMDxnhOjvm4KtlzNdu6pseOHWuM5+fn+9q+327zZO+v3+2YxpPoa86RMgAAjqAoAwDgCIoyAACOoCgDAOAIX0W5oaFBM2bMUEFBgUpLS7VgwQI1NzcPWqe7u1v19fUaP368xo0bp0WLFqmtrS3QQQNIL+QOIDG+inJTU5Pq6+u1f/9+vfnmm+rt7dW8efPU1dUVX+fxxx/XG2+8oa1bt6qpqUlnzpzRwoULAx84gPQxkrkjFAolvCRz20NZbDzPMy79/f3Gxba+3+3blu7ubuPS19dnXGzbKSwsNC75+fnGxe/rEtTr6NdwtuPrkqidO3cOur1p0yaVlpbq4MGDmj17tjo6OvSnP/1Jmzdv1re//W1J0saNG3Xrrbdq//79+ta3vuXn4QBkCHIHkJhhnVPu6OiQJBUXF0uSDh48qN7eXtXW1sbXueWWWzRp0iTt27fPuI1YLKZoNDpoAZDZyB2A2ZCL8sDAgFauXKlZs2Zp6tSpkqTW1lbl5+erqKho0LplZWVqbW01bqehoUGRSCS+VFZWDnVIANIAuQOwG3JRrq+v19GjR7Vly5ZhDWD16tXq6OiIL6dOnRrW9gC4jdwB2A1pms3ly5drx44d2rNnj6699tp4vLy8XD09PWpvbx/0F29bW5vKy8uN2wqHwwqHw0MZBoA0Q+4ALs9XUfY8TytWrNC2bdu0e/duVVVVDbp/+vTpysvLU2NjoxYtWiRJam5u1smTJ1VTUxPcqAGklZHMHUHMfR2UoOZets1x7Zff58Y2/lgsZoyPGmUuKVdddZWvuO0PsYu9CK7wM0d3os+9r6JcX1+vzZs36/XXX1dBQUH8XE8kEtGYMWMUiUT0yCOPaNWqVSouLlZhYaFWrFihmpoauieBLEbuABLjqyhv2LBBkjRnzpxB8Y0bN2rJkiWSpN/97nfKycnRokWLFIvFVFdXpz/84Q+BDBZAeiJ3AInx/fX1lYwePVrr16/X+vXrhzwoAJmF3AEkhrmvAQBwBEUZAABHDOmSKGQ2W0ehLT579uxkDgcYNj9dsi5K9jj9Pj/d3d3GeG5urjHutyvbtr5fQXW/jySOlAEAcARFGQAAR1CUAQBwBEUZAABHUJQBAHAE3de4hK3j0ha/7bbbkjkcIOME1Q0e1FzWfuXn5xvjeXl5xnhPT48xPjAwYIzburJtkt1l7ff1Gs54OFIGAMARFGUAABxBUQYAwBEUZQAAHEFRBgDAEXRfA8gooVAoLec8luxduzk55uMnW/dyUHNl28Zj676ORqPGuG2ubNv6XV1dvsaTqjnM/Ywn0TFypAwAgCMoygAAOIKiDACAIyjKAAA4wldRbmho0IwZM1RQUKDS0lItWLBAzc3Ng9aZM2dOvNHi4vLYY48FOmgA6YXcASTGV/d1U1OT6uvrNWPGDPX19elnP/uZ5s2bp2PHjg2aq3Tp0qVau3Zt/PbYsWODGzGAtDOSucNPJ67fLu1kd/kGNcey37jf/WptbTXGjx49aozn5uYa46dPnzbG+/r6jPFUdVmPJF9FeefOnYNub9q0SaWlpTp48KBmz54dj48dO1bl5eXBjBBA2iN3AIkZ1jnljo4OSVJxcfGg+J///GeVlJRo6tSpWr16tb766ivrNmKxmKLR6KAFQGYjdwBmQ548ZGBgQCtXrtSsWbM0derUePx73/uerrvuOlVUVOjIkSP6yU9+oubmZv3tb38zbqehoUHPPPPMUIcBIM2QOwC7kDfEL+mXLVumv//979q7d6+uvfZa63pvv/225s6dqxMnTmjKlCmX3B+LxRSLxeK3o9GoKisrhzIkBMR2vqikpMTXdkaNytwJ4zo6OlRYWJjqYaSlZOeOUaNGJXyu2LVzyjZBzdzl95yybSaxcDhsjP/61782xqdNm2aMNzU1GeNbt241xv+/OXCkBPE+8TxPfX19V8wdQ8qay5cv144dO7Rnz57Lfqgkqbq6WpKsH6xwOGx9gQFkFnIHcHm+irLneVqxYoW2bdum3bt3q6qq6or/5/Dhw5KkiRMnDmmAGHl1dXXG+F//+ldj/L333kvmcJABRjJ3BDH3td9u51R1ZadqOz09Pcb4rl27jPHPP//cGLcd+dq+rUuVoLrfE+GrKNfX12vz5s16/fXXVVBQEH/iIpGIxowZo08++USbN2/Wd77zHY0fP15HjhzR448/rtmzZ+v2228f8iABpDdyB5AYX0V5w4YNki5c5P91Gzdu1JIlS5Sfn6+33npL69atU1dXlyorK7Vo0SI9+eSTgQ0YQPohdwCJ8f319eVUVlZaT9wDyF7kDiAxzH0NAIAjKMoAADhiyNcpJ0s0GlUkEkn1MIDL4jpl91zMHX6uU/YrVd3XuLyg5gy3CeJ6cM/z1Nvbe8XcwZEyAACOoCgDAOAIijIAAI6gKAMA4AjnfjGAhgmkA96n7rn4mqTiteH94KagXpcgtpPo+9O5otzZ2ZnqIQBX1NnZyVUCjrmYO/r7+1M8EsDuSrnDuUuiBgYGdObMGRUUFKizs1OVlZU6depUVlx+cvGn59hfd3mep87OTlVUVFh/1g6pQe5gf12WaO5w7kg5Jycn/pNuF6/1KiwsTJsnPgjsr9s4QnYTuYP9dV0iuYM/9QEAcARFGQAARzhdlMPhsJ5++mmFw+FUD2VEsL9AMLLtvcX+Zg7nGr0AAMhWTh8pAwCQTSjKAAA4gqIMAIAjKMoAADjC6aK8fv16XX/99Ro9erSqq6v13nvvpXpIgdizZ4/uvfdeVVRUKBQKafv27YPu9zxPa9as0cSJEzVmzBjV1tbq+PHjqRlsABoaGjRjxgwVFBSotLRUCxYsUHNz86B1uru7VV9fr/Hjx2vcuHFatGiR2traUjRipLNMzRtSduWObM0bzhblv/zlL1q1apWefvppvf/++5o2bZrq6ur0+eefp3pow9bV1aVp06Zp/fr1xvufe+45vfjii/rjH/+od999V1dddZXq6urU3d09wiMNRlNTk+rr67V//369+eab6u3t1bx589TV1RVf5/HHH9cbb7yhrVu3qqmpSWfOnNHChQtTOGqko0zOG1J25Y6szRueo2bOnOnV19fHb/f393sVFRVeQ0NDCkcVPEnetm3b4rcHBga88vJy7/nnn4/H2tvbvXA47L322mspGGHwPv/8c0+S19TU5Hnehf3Ly8vztm7dGl/no48+8iR5+/btS9UwkYayJW94XvbljmzJG04eKff09OjgwYOqra2Nx3JyclRbW6t9+/alcGTJ19LSotbW1kH7HolEVF1dnTH73tHRIUkqLi6WJB08eFC9vb2D9vmWW27RpEmTMmafkXzZnDekzM8d2ZI3nCzKX375pfr7+1VWVjYoXlZWptbW1hSNamRc3L9M3feBgQGtXLlSs2bN0tSpUyVd2Of8/HwVFRUNWjdT9hkjI5vzhpTZuSOb8oZzvxKFzFZfX6+jR49q7969qR4KgDSRTXnDySPlkpIS5ebmXtJF19bWpvLy8hSNamRc3L9M3Pfly5drx44d2rVrV/wn9qQL+9zT06P29vZB62fCPmPkZHPekDI3d2Rb3nCyKOfn52v69OlqbGyMxwYGBtTY2KiampoUjiz5qqqqVF5ePmjfo9Go3n333bTdd8/ztHz5cm3btk1vv/22qqqqBt0/ffp05eXlDdrn5uZmnTx5Mm33GSMvm/OGlHm5I2vzRqo7zWy2bNnihcNhb9OmTd6xY8e8Rx991CsqKvJaW1tTPbRh6+zs9A4dOuQdOnTIk+S98MIL3qFDh7x//etfnud53m9+8xuvqKjIe/31170jR4549913n1dVVeWdP38+xSMfmmXLlnmRSMTbvXu399lnn8WXr776Kr7OY4895k2aNMl7++23vQMHDng1NTVeTU1NCkeNdJTJecPzsit3ZGvecLYoe57nvfTSS96kSZO8/Px8b+bMmd7+/ftTPaRA7Nq1y5N0ybJ48WLP8y5c2vDUU095ZWVlXjgc9ubOnes1NzendtDDYNpXSd7GjRvj65w/f9770Y9+5F199dXe2LFjvfvvv9/77LPPUjdopK1MzRuel125I1vzBj/dCACAI5w8pwwAQDaiKAMA4AiKMgAAjqAoAwDgCIoyAACOoCgDAOAIijIAAI6gKAMA4AiKMgAAjqAoAwDgCIoyAACOoCgDAOCI/wJQ6zndJN6LjAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, data in enumerate(test_dl):\n",
    "    # Get the input features and target labels, and put them on the GPU\n",
    "    inputs, labels = data[0].to(device), data[1].to(device)\n",
    "    break\n",
    "#print(inputs.shape)\n",
    "orig=inputs[0].reshape(28,28)\n",
    "output=myEncoder(inputs[0])\n",
    "print(output)\n",
    "output=myDecoder(output)\n",
    "\n",
    "output=output.detach().cpu().numpy()\n",
    "output=output.reshape(28,28)\n",
    "matplotlib.pyplot.subplot(2, 2, 1)\n",
    "matplotlib.pyplot.imshow(orig, cmap=\"gray\")\n",
    "matplotlib.pyplot.subplot(2, 2, 2)\n",
    "matplotlib.pyplot.imshow(output, cmap=\"gray\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
