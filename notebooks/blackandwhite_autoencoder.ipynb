{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2021 NVIDIA Corporation\n",
      "Built on Thu_Nov_18_09:45:30_PST_2021\n",
      "Cuda compilation tools, release 11.5, V11.5.119\n",
      "Build cuda_11.5.r11.5/compiler.30672275_0\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 17:02:53.647332: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-11 17:02:53.697211: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-11 17:02:54.575917: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os, sys # filesystem operations\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from argparse import Namespace\n",
    "import tensorflow.keras.datasets\n",
    "import matplotlib.pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n"
     ]
    }
   ],
   "source": [
    "# Preparing MNIST Dataset\n",
    "(x_train_orig, y_train), (x_test_orig, y_test) = tensorflow.keras.datasets.mnist.load_data()\n",
    "x_train_orig = x_train_orig.astype(\"float32\") / 255.0\n",
    "x_test_orig = x_test_orig.astype(\"float32\") / 255.0\n",
    "x_train = np.reshape(x_train_orig, newshape=(x_train_orig.shape[0], np.prod(x_train_orig.shape[1:])))\n",
    "x_test = np.reshape(x_test_orig, newshape=(x_test_orig.shape[0], np.prod(x_test_orig.shape[1:])))\n",
    "print(set(y_train))\n",
    "class DS():\n",
    "    def __init__(self, x_data, y_data):\n",
    "        self.data=x_data\n",
    "        self.labels=y_data\n",
    "        self.categories=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        #class_id = torch.as_tensor(self.categories.index(self.labels[idx]), dtype=torch.int64)\n",
    "        img=self.data[idx]\n",
    "        return torch.tensor(img), torch.tensor(img)\n",
    "train_data=DS(x_train, x_train)\n",
    "test_data=DS(x_test, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.dense_layer1 = nn.Linear(in_features=784, out_features=300)\n",
    "        self.dense_layer2 = nn.Linear(in_features=300, out_features=4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.dense_layer1(x))\n",
    "        x = F.leaky_relu(self.dense_layer2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dense_layer1 = nn.Linear(in_features=4, out_features=300)\n",
    "        self.dense_layer2 = nn.Linear(in_features=300, out_features=784)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.dense_layer1(x))\n",
    "        x = F.leaky_relu(self.dense_layer2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "myEncoder=Encoder()\n",
    "myDecoder=Decoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)\n",
    "myModel = Autoencoder(myEncoder, myDecoder)\n",
    "myModel = myModel.to(device)\n",
    "train_dl=torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_dl=torch.utils.data.DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference (model, val_dl):\n",
    "    all_preds=[]\n",
    "    all_labels=[]\n",
    "    correct_prediction = 0\n",
    "    total_prediction = 0\n",
    "\n",
    "    # Disable gradient updates\n",
    "    with torch.no_grad():\n",
    "        for data in val_dl:\n",
    "            # Get the input features and target labels, and put them on the GPU\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            # Normalize the inputs\n",
    "            inputs_m, inputs_s = inputs.mean(), inputs.std()\n",
    "            inputs = (inputs - inputs_m) / inputs_s\n",
    "\n",
    "            # Get predictions\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Get the predicted class with the highest score\n",
    "            _, prediction = torch.max(outputs,1)\n",
    "            # Count of predictions that matched the target label\n",
    "            correct_prediction += (prediction == labels).sum().item()\n",
    "            total_prediction += prediction.shape[0]\n",
    "            \n",
    "            all_preds.append(prediction.to(torch.device(\"cpu\")))\n",
    "            all_labels.append(labels.to(torch.device(\"cpu\")))\n",
    "    acc = correct_prediction/total_prediction\n",
    "    print(f'Accuracy: {acc:.2f}, Total items: {total_prediction}')\n",
    "    return all_preds, all_labels, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "testacclist=[]\n",
    "trainingacclist=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.37727333046496\n",
      "0\n",
      "28.449555350467563\n",
      "1\n",
      "28.599484337493777\n",
      "2\n",
      "28.789523208513856\n",
      "3\n",
      "28.963422434404492\n",
      "4\n",
      "29.071595123037696\n",
      "5\n",
      "29.119824070483446\n",
      "6\n",
      "29.120114982128143\n",
      "7\n",
      "29.04029551334679\n",
      "8\n",
      "28.946661619469523\n",
      "9\n",
      "28.801227239891887\n",
      "10\n",
      "28.629961039870977\n",
      "11\n",
      "28.454194024205208\n",
      "12\n",
      "28.27207527682185\n",
      "13\n",
      "28.081301415339112\n",
      "14\n",
      "27.907068265601993\n",
      "15\n",
      "27.752271046862006\n",
      "16\n",
      "27.58260765299201\n",
      "17\n",
      "27.41126362234354\n",
      "18\n",
      "27.267693359404802\n",
      "19\n",
      "27.095579659566283\n",
      "20\n",
      "26.951081104576588\n",
      "21\n",
      "26.784507635980844\n",
      "22\n",
      "26.61750976368785\n",
      "23\n",
      "26.471731536090374\n",
      "24\n",
      "26.32269816286862\n",
      "25\n",
      "26.18790509365499\n",
      "26\n",
      "26.04149341210723\n",
      "27\n",
      "25.905742160975933\n",
      "28\n",
      "25.78254819661379\n",
      "29\n",
      "25.67033783905208\n",
      "30\n",
      "25.556417755782604\n",
      "31\n",
      "25.460753194987774\n",
      "32\n",
      "25.372045824304223\n",
      "33\n",
      "25.298607235774398\n",
      "34\n",
      "25.236292270943522\n",
      "35\n",
      "25.188717301934958\n",
      "36\n",
      "25.146643608808517\n",
      "37\n",
      "25.11983721703291\n",
      "38\n",
      "25.10646310262382\n",
      "39\n"
     ]
    }
   ],
   "source": [
    "def training(model, train_dl, num_epochs, iteration):\n",
    "    # Loss Function, Optimizer and Scheduler  \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=0.0001)#01)\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.001,\n",
    "                                                steps_per_epoch=int(len(train_dl)),\n",
    "                                                epochs=num_epochs\n",
    "                                                )\n",
    "\n",
    "    # Repeat for each epoch\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct_prediction = 0\n",
    "        total_prediction = 0\n",
    "\n",
    "        # Repeat for each batch in the training set\n",
    "        for i, data in enumerate(train_dl):\n",
    "            # Get the input features and target labels, and put them on the GPU\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            #print(labels.is_cuda)\n",
    "            #print(np.shape(inputs))\n",
    "            # Normalize the inputs\n",
    "            #inputs_m, inputs_s = inputs.mean(), inputs.std()\n",
    "            #inputs = (inputs - inputs_m) / inputs_s\n",
    "            #print(inputs.is_cuda)\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            #print(outputs.is_cuda)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            # Keep stats for Loss and Accuracy\n",
    "            running_loss += loss.item()\n",
    "        print(running_loss)\n",
    "        print(epoch)\n",
    "for i in range(1):\n",
    "    num_epochs=40\n",
    "    iteration=i\n",
    "    training(myModel, train_dl, num_epochs, iteration)\n",
    "    #trainingacclist.append(trainacc)\n",
    "    \n",
    "    #temp1, temp2, testacc=inference(myModel, test_dl)\n",
    "    #testacclist.append(testacc)\n",
    "#x_axis = list(range(1, len(testacclist) + 1))\n",
    "#plt.plot(x_axis, trainingacclist, x_axis, testacclist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.4763, 6.7185, 8.3424, 4.3088], device='cuda:0',\n",
      "       grad_fn=<LeakyReluBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ce00cd73310>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, data in enumerate(test_dl):\n",
    "    # Get the input features and target labels, and put them on the GPU\n",
    "    inputs, labels = data[0].to(device), data[1].to(device)\n",
    "    break\n",
    "#print(inputs.shape)\n",
    "orig=inputs[0].reshape(28,28)\n",
    "output=myEncoder(inputs[0])\n",
    "print(output)\n",
    "output=myDecoder(output)\n",
    "\n",
    "output=output.detach().cpu().numpy()\n",
    "output=output.reshape(28,28)\n",
    "matplotlib.pyplot.subplot(2, 2, 1)\n",
    "matplotlib.pyplot.imshow(orig.detach().cpu(), cmap=\"gray\")\n",
    "matplotlib.pyplot.subplot(2, 2, 2)\n",
    "matplotlib.pyplot.imshow(output, cmap=\"gray\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
